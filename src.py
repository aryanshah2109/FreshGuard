# -*- coding: utf-8 -*-
"""FreshGuard-final

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/aryanshah2109/freshguard-final.435f22ee-5dea-431b-94f3-9360d0f5dbf2.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20250904/auto/storage/goog4_request%26X-Goog-Date%3D20250904T175952Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D196152b5af7b3ffdccde47337ddb004c533452c2644eb551ab31d416c4f7936def9117235363a4f34b4b57eb9eeee825a43781bdf03a4d8faec847c6986ded99eac909e374684c9ad5c58183928b29bea0499a1fb7b33f67017c7aeee7836b1e3096a6465e4b21bc91ad5056770a257ed8ef3fc80e9591d32100c269ecd3cf9aa1d6a054178b048d00dc806d11cfe803abbd73db9ce3d5c01faf4792e694bb1fab27f0002d2ca50335ef7470bd05388e5777b455aee84051a46c0cd1adbfbfd9a822a31a1cc4be18ef9d22e9c0b68c6cb89ebec3515f341a594d8bce389c73c195e9f89d106065edfd9ef86c7fc8f8274523db57599d86f5300bb391b06c20ed
"""

# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE
# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.
import kagglehub
kagglehub.login()

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.

aryanshah2109_freshguard_dataset_2_0_path = kagglehub.dataset_download('aryanshah2109/freshguard-dataset-2-0')
aryanshah2109_test_banana_spoiled_1_path = kagglehub.dataset_download('aryanshah2109/test-banana-spoiled-1')
aryanshah2109_test_foodfresh_path = kagglehub.dataset_download('aryanshah2109/test-foodfresh')

print('Data source import complete.')

tf.debugging.set_log_device_placement(True)

# 1. Imports and GPU setup
import os
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout
from tensorflow.keras.models import Model
from sklearn.utils.class_weight import compute_class_weight
from sklearn.model_selection import train_test_split

# 1a. Check GPU
gpus = tf.config.list_physical_devices('GPU')
if gpus:
    try:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
        print("GPU is available and memory growth enabled")
    except RuntimeError as e:
        print(e)
else:
    print("No GPU found, using CPU")
print("Num GPUs Available: ", len(gpus))


# 2. Dataset paths & parameters
DATASET_DIR = "/kaggle/input/freshguard-dataset-2-0/data_files"
IMG_SIZE = (224, 224)
BATCH_SIZE = 16  # smaller batch for small dataset
EPOCHS = 20
FINE_TUNE_LAYERS = 50  # number of top layers to unfreeze


# 3. Prepare file paths and labels

all_image_paths = []
all_labels = []

for class_name in os.listdir(DATASET_DIR):
    class_dir = os.path.join(DATASET_DIR, class_name)
    if os.path.isdir(class_dir):
        for img_name in os.listdir(class_dir):
            if img_name.lower().endswith((".jpg", ".jpeg", ".png")):
                all_image_paths.append(os.path.join(class_dir, img_name))
                all_labels.append(class_name)

# Create label mapping
unique_labels = sorted(list(set(all_labels)))
label_to_int = {label: i for i, label in enumerate(unique_labels)}
int_to_label = {i: label for i, label in enumerate(unique_labels)}
all_int_labels = [label_to_int[label] for label in all_labels]

# Train/validation split
X_train, X_val, y_train, y_val = train_test_split(
    all_image_paths, all_int_labels, test_size=0.2, random_state=42, stratify=all_int_labels
)


# 4. TF.data pipeline with augmentation
def preprocess_image(img_path, label, training=True):
    img = tf.io.read_file(img_path)
    img = tf.image.decode_jpeg(img, channels=3)
    img = tf.image.resize(img, IMG_SIZE)
    img = tf.cast(img, tf.float32) / 255.0

    if training:
        img = tf.image.random_flip_left_right(img)
        img = tf.image.random_brightness(img, 0.2)
        img = tf.image.random_contrast(img, 0.8, 1.2)

    return img, tf.one_hot(label, len(unique_labels))

def create_dataset(image_paths, labels, training=True):
    ds = tf.data.Dataset.from_tensor_slices((image_paths, labels))
    if training:
        ds = ds.shuffle(buffer_size=1000)
    ds = ds.map(lambda x, y: preprocess_image(x, y, training), num_parallel_calls=tf.data.AUTOTUNE)
    ds = ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)
    return ds

train_ds = create_dataset(X_train, y_train, training=True)
val_ds = create_dataset(X_val, y_val, training=False)


# 5. Compute class weights
class_weights = compute_class_weight(
    class_weight="balanced",
    classes=np.unique(y_train),
    y=y_train
)
class_weights = dict(enumerate(class_weights))
print("Class weights:", class_weights)


# 6. Build MobileNetV2 model
base_model = MobileNetV2(weights="imagenet", include_top=False, input_shape=(224,224,3))
base_model.trainable = True  # unfreeze entire base

x = GlobalAveragePooling2D()(base_model.output)
x = Dropout(0.3)(x)
output = Dense(len(unique_labels), activation="softmax")(x)

model = Model(inputs=base_model.input, outputs=output)
model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),
              loss="categorical_crossentropy",
              metrics=["accuracy"])
model.summary()


# 7. Train the model
history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=EPOCHS,
    class_weight=class_weights
)


# 8. Prediction function
def predict_image(img_path):
    img = tf.io.read_file(img_path)
    img = tf.image.decode_jpeg(img, channels=3)
    img = tf.image.resize(img, IMG_SIZE)
    img_array = tf.expand_dims(img, axis=0) / 255.0

    predictions = model.predict(img_array)
    pred_class = np.argmax(predictions[0])
    confidence = np.max(predictions[0])

    plt.imshow(img.numpy().astype("uint8"))
    plt.axis("off")
    plt.title(f"Prediction: {int_to_label[pred_class]} ({confidence*100:.2f}%)")
    plt.show()

    return int_to_label[pred_class], confidence

# Example usage:
# predict_image("/kaggle/input/test-banana-spoiled-1/IMG_2115.jpg")

# 9. Classification Report
from sklearn.metrics import classification_report, confusion_matrix
import pickle

y_true, y_pred = [], []

for imgs, labels in val_ds:
    preds = model.predict(imgs)
    y_pred.extend(np.argmax(preds, axis=1))
    y_true.extend(np.argmax(labels.numpy(), axis=1))

# Generate report
print("\nClassification Report:")
print(classification_report(y_true, y_pred, target_names=unique_labels))

print("\nConfusion Matrix:")
print(confusion_matrix(y_true, y_pred))

# 10. Save Model & Metadata
# Save Keras model
model.save("freshguard_model.h5")

# Save label mappings & training history using pickle
metadata = {
    "label_to_int": label_to_int,
    "int_to_label": int_to_label,
    "history": history.history
}
with open("freshguard_metadata.pkl", "wb") as f:
    pickle.dump(metadata, f)

print("Model saved as freshguard_model.h5")
print("Metadata saved as freshguard_metadata.pkl")

predict_image("/kaggle/input/test-banana-spoiled-1/IMG_2115.jpg")

predict_image('/kaggle/input/test-foodfresh/IMG_0244.jpg')

predict_image('/kaggle/input/test-foodfresh/IMG_0382.jpg')

predict_image('/kaggle/input/test-foodfresh/IMG_0382.jpg')

predict_image('/kaggle/input/test-foodfresh/IMG_2247.jpg')

predict_image('/kaggle/input/test-foodfresh/IMG_5188.jpg')

predict_image('/kaggle/input/test-foodfresh/IMG_7208.jpg')

predict_image('/kaggle/input/test-foodfresh/IMG_7438.jpg')

